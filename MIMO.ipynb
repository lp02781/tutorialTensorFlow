{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 210091.1094 - accuracy: 0.7112\n",
      "Epoch 2/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 58196.2852 - accuracy: 0.7620\n",
      "Epoch 3/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 7417.2251 - accuracy: 0.9432\n",
      "Epoch 4/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1211.0452 - accuracy: 0.9871\n",
      "Epoch 5/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 380.5471 - accuracy: 0.9890\n",
      "Epoch 6/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 173.2598 - accuracy: 0.9940\n",
      "Epoch 7/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 107.9577 - accuracy: 0.9940\n",
      "Epoch 8/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 72.6770 - accuracy: 0.9960\n",
      "Epoch 9/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 49.0983 - accuracy: 0.9970\n",
      "Epoch 10/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 38.3933 - accuracy: 0.9970\n",
      "Epoch 11/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 42.5243 - accuracy: 0.9970\n",
      "Epoch 12/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 29.4868 - accuracy: 0.9970\n",
      "Epoch 13/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 32.4458 - accuracy: 0.9970\n",
      "Epoch 14/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 33.8311 - accuracy: 0.9990\n",
      "Epoch 15/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 21.8640 - accuracy: 0.9980\n",
      "Epoch 16/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 19.7388 - accuracy: 0.9990\n",
      "Epoch 17/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 26.0068 - accuracy: 0.9990\n",
      "Epoch 18/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 19.9055 - accuracy: 0.9970\n",
      "Epoch 19/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 17.8506 - accuracy: 0.9980\n",
      "Epoch 20/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 15.0469 - accuracy: 0.9980\n",
      "Epoch 21/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 17.3917 - accuracy: 0.9960\n",
      "Epoch 22/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 19.4143 - accuracy: 0.9990\n",
      "Epoch 23/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 90.6376 - accuracy: 0.9940\n",
      "Epoch 24/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 46.4790 - accuracy: 0.9950\n",
      "Epoch 25/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 21.2200 - accuracy: 0.9950\n",
      "Epoch 26/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 9.8199 - accuracy: 0.9970\n",
      "Epoch 27/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 11.6486 - accuracy: 0.9980\n",
      "Epoch 28/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 10.4305 - accuracy: 0.9960\n",
      "Epoch 29/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 49.9728 - accuracy: 0.9920\n",
      "Epoch 30/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 55.1846 - accuracy: 0.9940\n",
      "Epoch 31/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 38.4264 - accuracy: 0.9980\n",
      "Epoch 32/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 24.0368 - accuracy: 0.9990\n",
      "Epoch 33/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 19.3628 - accuracy: 0.9980\n",
      "Epoch 34/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 12.6982 - accuracy: 0.9980\n",
      "Epoch 35/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 17.6079 - accuracy: 0.9990\n",
      "Epoch 36/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 24.7926 - accuracy: 0.9960\n",
      "Epoch 37/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 11.6662 - accuracy: 0.9980\n",
      "Epoch 38/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 17.5108 - accuracy: 0.9990\n",
      "Epoch 39/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 31.4028 - accuracy: 0.9960\n",
      "Epoch 40/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 14.0376 - accuracy: 0.9980\n",
      "Epoch 41/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 11.7714 - accuracy: 1.0000\n",
      "Epoch 42/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 7.4368 - accuracy: 0.9990\n",
      "Epoch 43/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 14.3361 - accuracy: 0.9970\n",
      "Epoch 44/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 17.7707 - accuracy: 0.9980\n",
      "Epoch 45/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 10.9658 - accuracy: 0.9990\n",
      "Epoch 46/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 9.0413 - accuracy: 0.9970\n",
      "Epoch 47/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 8.3756 - accuracy: 1.0000\n",
      "Epoch 48/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 17.6675 - accuracy: 0.9950\n",
      "Epoch 49/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 186.1994 - accuracy: 0.9841\n",
      "Epoch 50/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 57.6536 - accuracy: 0.9980\n",
      "Epoch 51/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 78.8142 - accuracy: 0.9970\n",
      "Epoch 52/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 14.6296 - accuracy: 0.9980\n",
      "Epoch 53/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 19.4137 - accuracy: 0.9980\n",
      "Epoch 54/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 22.8143 - accuracy: 0.9960\n",
      "Epoch 55/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 28.3892 - accuracy: 0.9960\n",
      "Epoch 56/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 14.9793 - accuracy: 0.9990\n",
      "Epoch 57/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 15.6566 - accuracy: 0.9970\n",
      "Epoch 58/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 22.5273 - accuracy: 0.9960\n",
      "Epoch 59/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 9.3461 - accuracy: 0.9980\n",
      "Epoch 60/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 13.7649 - accuracy: 0.9990\n",
      "Epoch 61/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 20.7334 - accuracy: 0.9960\n",
      "Epoch 62/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 20.2091 - accuracy: 0.9970\n",
      "Epoch 63/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 17.3590 - accuracy: 0.9970\n",
      "Epoch 64/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 21.4996 - accuracy: 0.9970\n",
      "Epoch 65/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 16.2709 - accuracy: 0.9970\n",
      "Epoch 66/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 25.3952 - accuracy: 0.9990\n",
      "Epoch 67/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 6.9133 - accuracy: 0.9980\n",
      "Epoch 68/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 11.9051 - accuracy: 0.9980\n",
      "Epoch 69/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 10.0544 - accuracy: 0.9970\n",
      "Epoch 70/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 10.9970 - accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 10.5377 - accuracy: 0.9980\n",
      "Epoch 72/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 23.4693 - accuracy: 0.9920\n",
      "Epoch 73/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 42.2870 - accuracy: 0.9980\n",
      "Epoch 74/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 12.2924 - accuracy: 0.9970\n",
      "Epoch 75/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 15.0347 - accuracy: 0.9990\n",
      "Epoch 76/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 35.7661 - accuracy: 0.9970\n",
      "Epoch 77/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 41.2077 - accuracy: 0.9980\n",
      "Epoch 78/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 242.4109 - accuracy: 0.9920\n",
      "Epoch 79/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 157.0898 - accuracy: 0.9940\n",
      "Epoch 80/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146.8229 - accuracy: 0.9900\n",
      "Epoch 81/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 78.0870 - accuracy: 0.9990\n",
      "Epoch 82/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 24.4453 - accuracy: 0.9990\n",
      "Epoch 83/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 16.3014 - accuracy: 0.9990\n",
      "Epoch 84/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 9.4894 - accuracy: 0.9990\n",
      "Epoch 85/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 5.6530 - accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 10.2660 - accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 7.4558 - accuracy: 0.9980\n",
      "Epoch 88/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 8.5033 - accuracy: 0.9980\n",
      "Epoch 89/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 5.3395 - accuracy: 0.9990\n",
      "Epoch 90/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 4.6776 - accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 11.3472 - accuracy: 0.9980\n",
      "Epoch 92/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 24.3661 - accuracy: 0.9990\n",
      "Epoch 93/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 8.4331 - accuracy: 0.9980\n",
      "Epoch 94/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 12.2133 - accuracy: 0.9970\n",
      "Epoch 95/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 21.4987 - accuracy: 0.9990\n",
      "Epoch 96/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 21.9565 - accuracy: 0.9980\n",
      "Epoch 97/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 24.1611 - accuracy: 0.9980\n",
      "Epoch 98/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 12.1235 - accuracy: 0.9970\n",
      "Epoch 99/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.7392 - accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 25.5574 - accuracy: 0.9970\n",
      "Epoch 101/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 12.9640 - accuracy: 0.9980\n",
      "Epoch 102/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 20.9685 - accuracy: 0.9990\n",
      "Epoch 103/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 20.2286 - accuracy: 0.9980\n",
      "Epoch 104/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 7.6563 - accuracy: 0.9990\n",
      "Epoch 105/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 10.3853 - accuracy: 0.9970\n",
      "Epoch 106/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 33.2916 - accuracy: 0.9970\n",
      "Epoch 107/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 11.5570 - accuracy: 0.9990\n",
      "Epoch 108/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 23.7368 - accuracy: 0.9980\n",
      "Epoch 109/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 12.1699 - accuracy: 0.9980\n",
      "Epoch 110/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 13.4371 - accuracy: 0.9970\n",
      "Epoch 111/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 20.9288 - accuracy: 0.9990\n",
      "Epoch 112/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 28.1595 - accuracy: 0.9980\n",
      "Epoch 113/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 13.7984 - accuracy: 0.9980\n",
      "Epoch 114/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 22.3378 - accuracy: 0.9990\n",
      "Epoch 115/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 13.2379 - accuracy: 0.9990\n",
      "Epoch 116/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 10.3042 - accuracy: 0.9980\n",
      "Epoch 117/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 12.7518 - accuracy: 0.9970\n",
      "Epoch 118/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 20.7457 - accuracy: 0.9970\n",
      "Epoch 119/300\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 25.9155 - accuracy: 0.9970\n",
      "Epoch 120/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 68.9494 - accuracy: 0.9960\n",
      "Epoch 121/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 25.6186 - accuracy: 0.9970\n",
      "Epoch 122/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 21.3008 - accuracy: 0.9990\n",
      "Epoch 123/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 89.4085 - accuracy: 0.9930\n",
      "Epoch 124/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 52.8890 - accuracy: 0.9990\n",
      "Epoch 125/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 23.6021 - accuracy: 0.9970\n",
      "Epoch 126/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 33.3160 - accuracy: 0.9980\n",
      "Epoch 127/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 115.9244 - accuracy: 0.9970\n",
      "Epoch 128/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 54.7793 - accuracy: 0.9960\n",
      "Epoch 129/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 17.2651 - accuracy: 0.9980\n",
      "Epoch 130/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 11.8802 - accuracy: 0.9980\n",
      "Epoch 131/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 11.5549 - accuracy: 0.9990\n",
      "Epoch 132/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 12.3799 - accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 7.8190 - accuracy: 0.9980\n",
      "Epoch 134/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 6.3793 - accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 12.5923 - accuracy: 0.9980\n",
      "Epoch 136/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 37.5040 - accuracy: 0.9970\n",
      "Epoch 137/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 73.7820 - accuracy: 0.9960\n",
      "Epoch 138/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 32.3740 - accuracy: 0.9960\n",
      "Epoch 139/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 53.0398 - accuracy: 0.9970\n",
      "Epoch 140/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 72.6602 - accuracy: 0.9960\n",
      "Epoch 141/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 38.8664 - accuracy: 0.9980\n",
      "Epoch 142/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 33.9390 - accuracy: 0.9950\n",
      "Epoch 143/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 23.5323 - accuracy: 0.9950\n",
      "Epoch 144/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 9.1977 - accuracy: 0.9970\n",
      "Epoch 145/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 11.5392 - accuracy: 0.9970\n",
      "Epoch 146/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 5.3848 - accuracy: 0.9990\n",
      "Epoch 147/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 9.0453 - accuracy: 0.9970\n",
      "Epoch 148/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 25.7855 - accuracy: 0.9990\n",
      "Epoch 149/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 53.7149 - accuracy: 0.9950\n",
      "Epoch 150/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 72.2215 - accuracy: 0.9960\n",
      "Epoch 151/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 367.2979 - accuracy: 0.9880\n",
      "Epoch 152/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133.5170 - accuracy: 0.9950\n",
      "Epoch 153/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 38.4706 - accuracy: 0.9980\n",
      "Epoch 154/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 18.3006 - accuracy: 0.9960\n",
      "Epoch 155/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 22.3676 - accuracy: 0.9970\n",
      "Epoch 156/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 15.6491 - accuracy: 0.9990\n",
      "Epoch 157/300\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 9.4435 - accuracy: 0.9970\n",
      "Epoch 158/300\n",
      " 1/32 [..............................] - ETA: 0s - loss: 12.4967 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv('~/tutorialTensorFlow/haha.csv') \n",
    "\n",
    "data = df.values\n",
    "X_data = data[:,:-2]\n",
    "Y_data = data[:,-2:]\n",
    "\n",
    "X = X_data[:-1000]\n",
    "X_test = X_data[-1000:]\n",
    "Y = Y_data[:-1000]\n",
    "Y_test = Y_data[-1000:]\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(2, activation= tf.keras.activations.linear)\n",
    "])\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(lr =0.001),loss='mean_squared_error',metrics=['accuracy'])\n",
    "r = model.fit(X, Y, epochs= 300)\n",
    "plt.plot(r.history['loss'],label = 'Training')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "Y_pred = model.predict(X_test)\n",
    "x_label = np.arange(1,1001,1)\n",
    "plt.figure()\n",
    "plt.subplot(311)\n",
    "plt.plot(x_label, Y_test[:,0], '-b', x_label, Y_pred[:,0], '-r')\n",
    "plt.subplot(312)\n",
    "plt.plot(x_label, Y_test[:,1], '-b', x_label, Y_pred[:,1], '-r')\n",
    "plt.show()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
